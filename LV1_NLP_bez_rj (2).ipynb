{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d16d58a5",
      "metadata": {
        "id": "d16d58a5"
      },
      "source": [
        "# LV1 – Obrada teksta i Part-of-Speech (POS) označavanje\n",
        "### Laboratorijska vježba 1\n",
        "**Tema:** Osnove obrade prirodnog jezika pomoću biblioteka spaCy i NLTK\n",
        "\n",
        "Ovaj notebook sadrži teorijski uvod, osnovne korake obrade teksta te zadatke za samostalni rad. Studenti mogu birati žele li koristiti *spaCy* ili *NLTK* biblioteku pri rješavanju zadataka."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "728e5e35",
      "metadata": {
        "id": "728e5e35"
      },
      "source": [
        "## Ciljevi vježbe\n",
        "- Upoznati osnovne korake obrade prirodnog jezika (NLP).\n",
        "- Primijeniti biblioteke **spaCy** i **NLTK** na obradu teksta.\n",
        "- Razumjeti i implementirati procese tokenizacije, uklanjanja zaustavnih riječi, lematizacije i POS označavanja.\n",
        "- Razviti sposobnost analize i interpretacije rezultata obrade teksta."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81c3ba0d",
      "metadata": {
        "id": "81c3ba0d"
      },
      "source": [
        "## 1. Instalacija potrebnih biblioteka"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy nltk matplotlib pandas\n",
        "\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIIjwtAUhRqm",
        "outputId": "2f2cd1a1-6675-4092-fc82-8babdbecf8e0",
        "collapsed": true
      },
      "id": "DIIjwtAUhRqm",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.8)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.8)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.10.5)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/12.8 MB\u001b[0m \u001b[31m320.2 kB/s\u001b[0m eta \u001b[36m0:00:27\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39059489",
      "metadata": {
        "id": "39059489"
      },
      "source": [
        "## 2. Tokenizacija\n",
        "**Opis:** Tokenizacija je proces razdvajanja teksta na manje jedinice – tokene (riječi, interpunkcijske znakove itd.).\n",
        "\n",
        "U nastavku su prikazana dva načina tokenizacije: pomoću *spaCy* i pomoću *NLTK*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a48c5bc1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a48c5bc1",
        "outputId": "dcd97dcd-6b93-466d-8675-91f28115976b",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural\n",
            "Language\n",
            "Processing\n",
            "enables\n",
            "computers\n",
            "to\n",
            "understand\n",
            "human\n",
            "language\n",
            ".\n"
          ]
        }
      ],
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "text = 'Natural Language Processing enables computers to understand human language.'\n",
        "doc = nlp(text)\n",
        "for token in doc:\n",
        "    print(token.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0fee9276",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fee9276",
        "outputId": "86aff4db-833d-492a-d49d-120c39bec9ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'Language', 'Processing', 'enables', 'computers', 'to', 'understand', 'human', 'language', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "text = 'Natural Language Processing enables computers to understand human language.'\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95c3a757",
      "metadata": {
        "id": "95c3a757"
      },
      "source": [
        "### Zadatak 1\n",
        "Upiši vlastiti tekst i izvrši tokenizaciju pomoću obje biblioteke."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "2dd9a883",
      "metadata": {
        "id": "2dd9a883",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b9eae8-604e-4ee2-a29c-3b180939e39e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Izvorni tekst:\n",
            "\n",
            "The team played an intense match last night, delivering one of their strongest performances this season.\n",
            "Throughout the match, the team demonstrated exceptional teamwork, discipline, and determination.\n",
            "The coach repeatedly emphasized how important teamwork was for maintaining control during the most difficult moments of the match.\n",
            "Several players mentioned that the team had trained specifically to improve their teamwork and communication, which clearly paid off.\n",
            "Fans celebrated loudly after the match, recognizing that the team’s victory was crucial for improving their position in the championship.\n",
            "During the press conference, the coach praised the players for their strategy, dedication, and ability to adapt as the match progressed.\n",
            "He highlighted that every victory strengthens the team’s confidence and prepares them for future challenges.\n",
            "The upcoming match is even more important, as the team is competing for a spot in the finals.\n",
            "Analysts agree that if the team continues to show this level of teamwork and discipline, they have a strong chance of winning the entire championship.\n",
            "In the end, the team proved that success is not just about individual talent but about unity, effort, and the shared goal of winning the championship.\n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Tokenizacija sa spaCy:\n",
            "['\\n', 'The', 'team', 'played', 'an', 'intense', 'match', 'last', 'night', ',', 'delivering', 'one', 'of', 'their', 'strongest', 'performances', 'this', 'season', '.', '\\n', 'Throughout', 'the', 'match', ',', 'the', 'team', 'demonstrated', 'exceptional', 'teamwork', ',', 'discipline', ',', 'and', 'determination', '.', '\\n', 'The', 'coach', 'repeatedly', 'emphasized', 'how', 'important', 'teamwork', 'was', 'for', 'maintaining', 'control', 'during', 'the', 'most', 'difficult', 'moments', 'of', 'the', 'match', '.', '\\n', 'Several', 'players', 'mentioned', 'that', 'the', 'team', 'had', 'trained', 'specifically', 'to', 'improve', 'their', 'teamwork', 'and', 'communication', ',', 'which', 'clearly', 'paid', 'off', '.', '\\n', 'Fans', 'celebrated', 'loudly', 'after', 'the', 'match', ',', 'recognizing', 'that', 'the', 'team', '’s', 'victory', 'was', 'crucial', 'for', 'improving', 'their', 'position', 'in', 'the', 'championship', '.', '\\n', 'During', 'the', 'press', 'conference', ',', 'the', 'coach', 'praised', 'the', 'players', 'for', 'their', 'strategy', ',', 'dedication', ',', 'and', 'ability', 'to', 'adapt', 'as', 'the', 'match', 'progressed', '.', '\\n', 'He', 'highlighted', 'that', 'every', 'victory', 'strengthens', 'the', 'team', '’s', 'confidence', 'and', 'prepares', 'them', 'for', 'future', 'challenges', '.', '\\n', 'The', 'upcoming', 'match', 'is', 'even', 'more', 'important', ',', 'as', 'the', 'team', 'is', 'competing', 'for', 'a', 'spot', 'in', 'the', 'finals', '.', '\\n', 'Analysts', 'agree', 'that', 'if', 'the', 'team', 'continues', 'to', 'show', 'this', 'level', 'of', 'teamwork', 'and', 'discipline', ',', 'they', 'have', 'a', 'strong', 'chance', 'of', 'winning', 'the', 'entire', 'championship', '.', '\\n', 'In', 'the', 'end', ',', 'the', 'team', 'proved', 'that', 'success', 'is', 'not', 'just', 'about', 'individual', 'talent', 'but', 'about', 'unity', ',', 'effort', ',', 'and', 'the', 'shared', 'goal', 'of', 'winning', 'the', 'championship', '.', '\\n']\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Tokenizacija s NLTK:\n",
            "['The', 'team', 'played', 'an', 'intense', 'match', 'last', 'night', ',', 'delivering', 'one', 'of', 'their', 'strongest', 'performances', 'this', 'season', '.', 'Throughout', 'the', 'match', ',', 'the', 'team', 'demonstrated', 'exceptional', 'teamwork', ',', 'discipline', ',', 'and', 'determination', '.', 'The', 'coach', 'repeatedly', 'emphasized', 'how', 'important', 'teamwork', 'was', 'for', 'maintaining', 'control', 'during', 'the', 'most', 'difficult', 'moments', 'of', 'the', 'match', '.', 'Several', 'players', 'mentioned', 'that', 'the', 'team', 'had', 'trained', 'specifically', 'to', 'improve', 'their', 'teamwork', 'and', 'communication', ',', 'which', 'clearly', 'paid', 'off', '.', 'Fans', 'celebrated', 'loudly', 'after', 'the', 'match', ',', 'recognizing', 'that', 'the', 'team', '’', 's', 'victory', 'was', 'crucial', 'for', 'improving', 'their', 'position', 'in', 'the', 'championship', '.', 'During', 'the', 'press', 'conference', ',', 'the', 'coach', 'praised', 'the', 'players', 'for', 'their', 'strategy', ',', 'dedication', ',', 'and', 'ability', 'to', 'adapt', 'as', 'the', 'match', 'progressed', '.', 'He', 'highlighted', 'that', 'every', 'victory', 'strengthens', 'the', 'team', '’', 's', 'confidence', 'and', 'prepares', 'them', 'for', 'future', 'challenges', '.', 'The', 'upcoming', 'match', 'is', 'even', 'more', 'important', ',', 'as', 'the', 'team', 'is', 'competing', 'for', 'a', 'spot', 'in', 'the', 'finals', '.', 'Analysts', 'agree', 'that', 'if', 'the', 'team', 'continues', 'to', 'show', 'this', 'level', 'of', 'teamwork', 'and', 'discipline', ',', 'they', 'have', 'a', 'strong', 'chance', 'of', 'winning', 'the', 'entire', 'championship', '.', 'In', 'the', 'end', ',', 'the', 'team', 'proved', 'that', 'success', 'is', 'not', 'just', 'about', 'individual', 'talent', 'but', 'about', 'unity', ',', 'effort', ',', 'and', 'the', 'shared', 'goal', 'of', 'winning', 'the', 'championship', '.']\n",
            "\n",
            "Uočene razlike:\n",
            "Spacy prepoznaje /n kao znak.\n",
            "NLTK-ova word_tokenize funkcija je jednostavnija i fokusira se na razdvajanje riječi i interpunkcije.\n"
          ]
        }
      ],
      "source": [
        "my_text = (\n",
        "    \"\"\"\n",
        "The team played an intense match last night, delivering one of their strongest performances this season.\n",
        "Throughout the match, the team demonstrated exceptional teamwork, discipline, and determination.\n",
        "The coach repeatedly emphasized how important teamwork was for maintaining control during the most difficult moments of the match.\n",
        "Several players mentioned that the team had trained specifically to improve their teamwork and communication, which clearly paid off.\n",
        "Fans celebrated loudly after the match, recognizing that the team’s victory was crucial for improving their position in the championship.\n",
        "During the press conference, the coach praised the players for their strategy, dedication, and ability to adapt as the match progressed.\n",
        "He highlighted that every victory strengthens the team’s confidence and prepares them for future challenges.\n",
        "The upcoming match is even more important, as the team is competing for a spot in the finals.\n",
        "Analysts agree that if the team continues to show this level of teamwork and discipline, they have a strong chance of winning the entire championship.\n",
        "In the end, the team proved that success is not just about individual talent but about unity, effort, and the shared goal of winning the championship.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "print(\"Izvorni tekst:\")\n",
        "print(my_text)\n",
        "print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
        "\n",
        "print(\"Tokenizacija sa spaCy:\")\n",
        "doc_custom = nlp(my_text)\n",
        "spacy_tokens = [token.text for token in doc_custom]\n",
        "print(spacy_tokens)\n",
        "\n",
        "print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
        "\n",
        "print(\"Tokenizacija s NLTK:\")\n",
        "nltk_tokens = word_tokenize(my_text)\n",
        "print(nltk_tokens)\n",
        "\n",
        "print(\"\\nUočene razlike:\")\n",
        "print(\"Spacy prepoznaje /n kao znak.\")\n",
        "print(\"NLTK-ova word_tokenize funkcija je jednostavnija i fokusira se na razdvajanje riječi i interpunkcije.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "051fae1c",
      "metadata": {
        "id": "051fae1c"
      },
      "source": [
        "## 3. Uklanjanje zaustavnih riječi (Stopwords)\n",
        "Zaustavne riječi su česte riječi koje ne doprinose značenju teksta (npr. the, is, in...)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bf13e4d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf13e4d3",
        "outputId": "9f25eedc-9538-4532-e6f1-4bc2571af202"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'Language', 'Processing', 'enables', 'computers', 'understand', 'human', 'language', '.']\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(text)\n",
        "filtered_spacy = [token.text for token in doc if not token.is_stop]\n",
        "print(filtered_spacy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bcb3dc46",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcb3dc46",
        "outputId": "61031c01-d6df-4b2c-cfa3-6edc915a1d30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'Language', 'Processing', 'enables', 'computers', 'understand', 'human', 'language', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_nltk = [word for word in tokens if word.lower() not in stop_words]\n",
        "print(filtered_nltk)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5538038",
      "metadata": {
        "id": "a5538038"
      },
      "source": [
        "### Zadatak 2\n",
        "Ukloni zaustavne riječi iz vlastitog teksta pomoću obje biblioteke."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "37d3c0f3",
      "metadata": {
        "id": "37d3c0f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14023807-35d1-4d4a-daf2-4d6f17913908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Izvorni tekst:\n",
            "\n",
            "The team played an intense match last night, delivering one of their strongest performances this season.\n",
            "Throughout the match, the team demonstrated exceptional teamwork, discipline, and determination.\n",
            "The coach repeatedly emphasized how important teamwork was for maintaining control during the most difficult moments of the match.\n",
            "Several players mentioned that the team had trained specifically to improve their teamwork and communication, which clearly paid off.\n",
            "Fans celebrated loudly after the match, recognizing that the team’s victory was crucial for improving their position in the championship.\n",
            "During the press conference, the coach praised the players for their strategy, dedication, and ability to adapt as the match progressed.\n",
            "He highlighted that every victory strengthens the team’s confidence and prepares them for future challenges.\n",
            "The upcoming match is even more important, as the team is competing for a spot in the finals.\n",
            "Analysts agree that if the team continues to show this level of teamwork and discipline, they have a strong chance of winning the entire championship.\n",
            "In the end, the team proved that success is not just about individual talent but about unity, effort, and the shared goal of winning the championship.\n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Uklanjanje stop riječi sa spaCy:\n",
            "['\\n', 'team', 'played', 'intense', 'match', 'night', ',', 'delivering', 'strongest', 'performances', 'season', '.', '\\n', 'match', ',', 'team', 'demonstrated', 'exceptional', 'teamwork', ',', 'discipline', ',', 'determination', '.', '\\n', 'coach', 'repeatedly', 'emphasized', 'important', 'teamwork', 'maintaining', 'control', 'difficult', 'moments', 'match', '.', '\\n', 'players', 'mentioned', 'team', 'trained', 'specifically', 'improve', 'teamwork', 'communication', ',', 'clearly', 'paid', '.', '\\n', 'Fans', 'celebrated', 'loudly', 'match', ',', 'recognizing', 'team', 'victory', 'crucial', 'improving', 'position', 'championship', '.', '\\n', 'press', 'conference', ',', 'coach', 'praised', 'players', 'strategy', ',', 'dedication', ',', 'ability', 'adapt', 'match', 'progressed', '.', '\\n', 'highlighted', 'victory', 'strengthens', 'team', 'confidence', 'prepares', 'future', 'challenges', '.', '\\n', 'upcoming', 'match', 'important', ',', 'team', 'competing', 'spot', 'finals', '.', '\\n', 'Analysts', 'agree', 'team', 'continues', 'level', 'teamwork', 'discipline', ',', 'strong', 'chance', 'winning', 'entire', 'championship', '.', '\\n', 'end', ',', 'team', 'proved', 'success', 'individual', 'talent', 'unity', ',', 'effort', ',', 'shared', 'goal', 'winning', 'championship', '.', '\\n']\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Uklanjanje stop riječi s NLTK:\n",
            "['team', 'played', 'intense', 'match', 'last', 'night', ',', 'delivering', 'one', 'strongest', 'performances', 'season', '.', 'Throughout', 'match', ',', 'team', 'demonstrated', 'exceptional', 'teamwork', ',', 'discipline', ',', 'determination', '.', 'coach', 'repeatedly', 'emphasized', 'important', 'teamwork', 'maintaining', 'control', 'difficult', 'moments', 'match', '.', 'Several', 'players', 'mentioned', 'team', 'trained', 'specifically', 'improve', 'teamwork', 'communication', ',', 'clearly', 'paid', '.', 'Fans', 'celebrated', 'loudly', 'match', ',', 'recognizing', 'team', '’', 'victory', 'crucial', 'improving', 'position', 'championship', '.', 'press', 'conference', ',', 'coach', 'praised', 'players', 'strategy', ',', 'dedication', ',', 'ability', 'adapt', 'match', 'progressed', '.', 'highlighted', 'every', 'victory', 'strengthens', 'team', '’', 'confidence', 'prepares', 'future', 'challenges', '.', 'upcoming', 'match', 'even', 'important', ',', 'team', 'competing', 'spot', 'finals', '.', 'Analysts', 'agree', 'team', 'continues', 'show', 'level', 'teamwork', 'discipline', ',', 'strong', 'chance', 'winning', 'entire', 'championship', '.', 'end', ',', 'team', 'proved', 'success', 'individual', 'talent', 'unity', ',', 'effort', ',', 'shared', 'goal', 'winning', 'championship', '.']\n",
            "\n",
            "Napomena:\n",
            "- spaCy koristi svoj jezični model za određivanje stop-riječi.\n",
            "- NLTK ima širu listu i često uklanja dodatne riječi poput 'can', 'we'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "print(\"Izvorni tekst:\")\n",
        "print(my_text)\n",
        "print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
        "\n",
        "print(\"Uklanjanje stop riječi sa spaCy:\")\n",
        "doc_custom = nlp(my_text)\n",
        "spacy_filtered = [token.text for token in doc_custom if not token.is_stop]\n",
        "print(spacy_filtered)\n",
        "\n",
        "print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
        "\n",
        "print(\"Uklanjanje stop riječi s NLTK:\")\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "nltk_filtered = [w for w in nltk_tokens if w.lower() not in stop_words]\n",
        "print(nltk_filtered)\n",
        "\n",
        "print(\"\\nNapomena:\")\n",
        "print(\"- spaCy koristi svoj jezični model za određivanje stop-riječi.\")\n",
        "print(\"- NLTK ima širu listu i često uklanja dodatne riječi poput 'can', 'we'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae512ad4",
      "metadata": {
        "id": "ae512ad4"
      },
      "source": [
        "## 4. Lematizacija\n",
        "Lematizacija svodi riječi na osnovni oblik (lemu)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "41ceba60",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41ceba60",
        "outputId": "c6e5d38c-48cd-4780-be93-09c86919e811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural         → Natural\n",
            "Language        → Language\n",
            "Processing      → processing\n",
            "enables         → enable\n",
            "computers       → computer\n",
            "to              → to\n",
            "understand      → understand\n",
            "human           → human\n",
            "language        → language\n",
            ".               → .\n"
          ]
        }
      ],
      "source": [
        "#Primjer: Lemmatizacija sa spaCy\n",
        "for token in doc:\n",
        "    print(f'{token.text:15} → {token.lemma_}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "797452a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "797452a0",
        "outputId": "c71ad2e9-f342-48bc-a41f-3cf8800932a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'Language', 'Processing', 'enable', 'computer', 'to', 'understand', 'human', 'language', '.']\n"
          ]
        }
      ],
      "source": [
        "#Primjer: Lemmatizacija s NLTK\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "pos_tags = pos_tag(tokens)\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'): return wordnet.ADJ\n",
        "    elif tag.startswith('V'): return wordnet.VERB\n",
        "    elif tag.startswith('N'): return wordnet.NOUN\n",
        "    elif tag.startswith('R'): return wordnet.ADV\n",
        "    else: return wordnet.NOUN\n",
        "lemmas = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
        "print(lemmas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44f47cbd",
      "metadata": {
        "id": "44f47cbd"
      },
      "source": [
        "### Zadatak 3\n",
        "Primijeni lematizaciju na vlastiti tekst i usporedi rezultate između spaCy i NLTK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "a357e693",
      "metadata": {
        "id": "a357e693",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab758a1-3f8b-447c-f088-3204c4ec8128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Izvorni tekst:\n",
            "\n",
            "The team played an intense match last night, delivering one of their strongest performances this season.\n",
            "Throughout the match, the team demonstrated exceptional teamwork, discipline, and determination.\n",
            "The coach repeatedly emphasized how important teamwork was for maintaining control during the most difficult moments of the match.\n",
            "Several players mentioned that the team had trained specifically to improve their teamwork and communication, which clearly paid off.\n",
            "Fans celebrated loudly after the match, recognizing that the team’s victory was crucial for improving their position in the championship.\n",
            "During the press conference, the coach praised the players for their strategy, dedication, and ability to adapt as the match progressed.\n",
            "He highlighted that every victory strengthens the team’s confidence and prepares them for future challenges.\n",
            "The upcoming match is even more important, as the team is competing for a spot in the finals.\n",
            "Analysts agree that if the team continues to show this level of teamwork and discipline, they have a strong chance of winning the entire championship.\n",
            "In the end, the team proved that success is not just about individual talent but about unity, effort, and the shared goal of winning the championship.\n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Lematizacija sa spaCy (token -> lemma):\n",
            "\n",
            "               -> \n",
            "\n",
            "The             -> the\n",
            "team            -> team\n",
            "played          -> play\n",
            "an              -> an\n",
            "intense         -> intense\n",
            "match           -> match\n",
            "last            -> last\n",
            "night           -> night\n",
            ",               -> ,\n",
            "delivering      -> deliver\n",
            "one             -> one\n",
            "of              -> of\n",
            "their           -> their\n",
            "strongest       -> strong\n",
            "performances    -> performance\n",
            "this            -> this\n",
            "season          -> season\n",
            ".               -> .\n",
            "\n",
            "               -> \n",
            "\n",
            "Throughout      -> throughout\n",
            "the             -> the\n",
            "match           -> match\n",
            ",               -> ,\n",
            "the             -> the\n",
            "team            -> team\n",
            "demonstrated    -> demonstrate\n",
            "exceptional     -> exceptional\n",
            "teamwork        -> teamwork\n",
            ",               -> ,\n",
            "discipline      -> discipline\n",
            ",               -> ,\n",
            "and             -> and\n",
            "determination   -> determination\n",
            ".               -> .\n",
            "\n",
            "               -> \n",
            "\n",
            "The             -> the\n",
            "coach           -> coach\n",
            "repeatedly      -> repeatedly\n",
            "emphasized      -> emphasize\n",
            "how             -> how\n",
            "important       -> important\n",
            "teamwork        -> teamwork\n",
            "was             -> be\n",
            "for             -> for\n",
            "maintaining     -> maintain\n",
            "control         -> control\n",
            "during          -> during\n",
            "the             -> the\n",
            "most            -> most\n",
            "difficult       -> difficult\n",
            "moments         -> moment\n",
            "of              -> of\n",
            "the             -> the\n",
            "match           -> match\n",
            ".               -> .\n",
            "\n",
            "               -> \n",
            "\n",
            "Several         -> several\n",
            "players         -> player\n",
            "mentioned       -> mention\n",
            "that            -> that\n",
            "the             -> the\n",
            "team            -> team\n",
            "had             -> have\n",
            "trained         -> train\n",
            "specifically    -> specifically\n",
            "to              -> to\n",
            "improve         -> improve\n",
            "their           -> their\n",
            "teamwork        -> teamwork\n",
            "and             -> and\n",
            "communication   -> communication\n",
            ",               -> ,\n",
            "which           -> which\n",
            "clearly         -> clearly\n",
            "paid            -> pay\n",
            "off             -> off\n",
            ".               -> .\n",
            "\n",
            "               -> \n",
            "\n",
            "Fans            -> fan\n",
            "celebrated      -> celebrate\n",
            "loudly          -> loudly\n",
            "after           -> after\n",
            "the             -> the\n",
            "match           -> match\n",
            ",               -> ,\n",
            "recognizing     -> recognize\n",
            "that            -> that\n",
            "the             -> the\n",
            "team            -> team\n",
            "’s              -> ’s\n",
            "victory         -> victory\n",
            "was             -> be\n",
            "crucial         -> crucial\n",
            "for             -> for\n",
            "improving       -> improve\n",
            "their           -> their\n",
            "position        -> position\n",
            "in              -> in\n",
            "the             -> the\n",
            "championship    -> championship\n",
            ".               -> .\n",
            "\n",
            "               -> \n",
            "\n",
            "During          -> during\n",
            "the             -> the\n",
            "press           -> press\n",
            "conference      -> conference\n",
            ",               -> ,\n",
            "the             -> the\n",
            "coach           -> coach\n",
            "praised         -> praise\n",
            "the             -> the\n",
            "players         -> player\n",
            "for             -> for\n",
            "their           -> their\n",
            "strategy        -> strategy\n",
            ",               -> ,\n",
            "dedication      -> dedication\n",
            ",               -> ,\n",
            "and             -> and\n",
            "ability         -> ability\n",
            "to              -> to\n",
            "adapt           -> adapt\n",
            "as              -> as\n",
            "the             -> the\n",
            "match           -> match\n",
            "progressed      -> progress\n",
            ".               -> .\n",
            "\n",
            "               -> \n",
            "\n",
            "He              -> he\n",
            "highlighted     -> highlight\n",
            "that            -> that\n",
            "every           -> every\n",
            "victory         -> victory\n",
            "strengthens     -> strengthen\n",
            "the             -> the\n",
            "team            -> team\n",
            "’s              -> ’s\n",
            "confidence      -> confidence\n",
            "and             -> and\n",
            "prepares        -> prepare\n",
            "them            -> they\n",
            "for             -> for\n",
            "future          -> future\n",
            "challenges      -> challenge\n",
            ".               -> .\n",
            "\n",
            "               -> \n",
            "\n",
            "The             -> the\n",
            "upcoming        -> upcoming\n",
            "match           -> match\n",
            "is              -> be\n",
            "even            -> even\n",
            "more            -> more\n",
            "important       -> important\n",
            ",               -> ,\n",
            "as              -> as\n",
            "the             -> the\n",
            "team            -> team\n",
            "is              -> be\n",
            "competing       -> compete\n",
            "for             -> for\n",
            "a               -> a\n",
            "spot            -> spot\n",
            "in              -> in\n",
            "the             -> the\n",
            "finals          -> final\n",
            ".               -> .\n",
            "\n",
            "               -> \n",
            "\n",
            "Analysts        -> analyst\n",
            "agree           -> agree\n",
            "that            -> that\n",
            "if              -> if\n",
            "the             -> the\n",
            "team            -> team\n",
            "continues       -> continue\n",
            "to              -> to\n",
            "show            -> show\n",
            "this            -> this\n",
            "level           -> level\n",
            "of              -> of\n",
            "teamwork        -> teamwork\n",
            "and             -> and\n",
            "discipline      -> discipline\n",
            ",               -> ,\n",
            "they            -> they\n",
            "have            -> have\n",
            "a               -> a\n",
            "strong          -> strong\n",
            "chance          -> chance\n",
            "of              -> of\n",
            "winning         -> win\n",
            "the             -> the\n",
            "entire          -> entire\n",
            "championship    -> championship\n",
            ".               -> .\n",
            "\n",
            "               -> \n",
            "\n",
            "In              -> in\n",
            "the             -> the\n",
            "end             -> end\n",
            ",               -> ,\n",
            "the             -> the\n",
            "team            -> team\n",
            "proved          -> prove\n",
            "that            -> that\n",
            "success         -> success\n",
            "is              -> be\n",
            "not             -> not\n",
            "just            -> just\n",
            "about           -> about\n",
            "individual      -> individual\n",
            "talent          -> talent\n",
            "but             -> but\n",
            "about           -> about\n",
            "unity           -> unity\n",
            ",               -> ,\n",
            "effort          -> effort\n",
            ",               -> ,\n",
            "and             -> and\n",
            "the             -> the\n",
            "shared          -> share\n",
            "goal            -> goal\n",
            "of              -> of\n",
            "winning         -> win\n",
            "the             -> the\n",
            "championship    -> championship\n",
            ".               -> .\n",
            "\n",
            "               -> \n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Lematizacija s NLTK (token -> lemma):\n",
            "The             -> The\n",
            "team            -> team\n",
            "played          -> play\n",
            "an              -> an\n",
            "intense         -> intense\n",
            "match           -> match\n",
            "last            -> last\n",
            "night           -> night\n",
            ",               -> ,\n",
            "delivering      -> deliver\n",
            "one             -> one\n",
            "of              -> of\n",
            "their           -> their\n",
            "strongest       -> strong\n",
            "performances    -> performance\n",
            "this            -> this\n",
            "season          -> season\n",
            ".               -> .\n",
            "Throughout      -> Throughout\n",
            "the             -> the\n",
            "match           -> match\n",
            ",               -> ,\n",
            "the             -> the\n",
            "team            -> team\n",
            "demonstrated    -> demonstrate\n",
            "exceptional     -> exceptional\n",
            "teamwork        -> teamwork\n",
            ",               -> ,\n",
            "discipline      -> discipline\n",
            ",               -> ,\n",
            "and             -> and\n",
            "determination   -> determination\n",
            ".               -> .\n",
            "The             -> The\n",
            "coach           -> coach\n",
            "repeatedly      -> repeatedly\n",
            "emphasized      -> emphasize\n",
            "how             -> how\n",
            "important       -> important\n",
            "teamwork        -> teamwork\n",
            "was             -> be\n",
            "for             -> for\n",
            "maintaining     -> maintain\n",
            "control         -> control\n",
            "during          -> during\n",
            "the             -> the\n",
            "most            -> most\n",
            "difficult       -> difficult\n",
            "moments         -> moment\n",
            "of              -> of\n",
            "the             -> the\n",
            "match           -> match\n",
            ".               -> .\n",
            "Several         -> Several\n",
            "players         -> player\n",
            "mentioned       -> mention\n",
            "that            -> that\n",
            "the             -> the\n",
            "team            -> team\n",
            "had             -> have\n",
            "trained         -> train\n",
            "specifically    -> specifically\n",
            "to              -> to\n",
            "improve         -> improve\n",
            "their           -> their\n",
            "teamwork        -> teamwork\n",
            "and             -> and\n",
            "communication   -> communication\n",
            ",               -> ,\n",
            "which           -> which\n",
            "clearly         -> clearly\n",
            "paid            -> pay\n",
            "off             -> off\n",
            ".               -> .\n",
            "Fans            -> Fans\n",
            "celebrated      -> celebrate\n",
            "loudly          -> loudly\n",
            "after           -> after\n",
            "the             -> the\n",
            "match           -> match\n",
            ",               -> ,\n",
            "recognizing     -> recognize\n",
            "that            -> that\n",
            "the             -> the\n",
            "team            -> team\n",
            "’               -> ’\n",
            "s               -> s\n",
            "victory         -> victory\n",
            "was             -> be\n",
            "crucial         -> crucial\n",
            "for             -> for\n",
            "improving       -> improve\n",
            "their           -> their\n",
            "position        -> position\n",
            "in              -> in\n",
            "the             -> the\n",
            "championship    -> championship\n",
            ".               -> .\n",
            "During          -> During\n",
            "the             -> the\n",
            "press           -> press\n",
            "conference      -> conference\n",
            ",               -> ,\n",
            "the             -> the\n",
            "coach           -> coach\n",
            "praised         -> praise\n",
            "the             -> the\n",
            "players         -> player\n",
            "for             -> for\n",
            "their           -> their\n",
            "strategy        -> strategy\n",
            ",               -> ,\n",
            "dedication      -> dedication\n",
            ",               -> ,\n",
            "and             -> and\n",
            "ability         -> ability\n",
            "to              -> to\n",
            "adapt           -> adapt\n",
            "as              -> a\n",
            "the             -> the\n",
            "match           -> match\n",
            "progressed      -> progress\n",
            ".               -> .\n",
            "He              -> He\n",
            "highlighted     -> highlight\n",
            "that            -> that\n",
            "every           -> every\n",
            "victory         -> victory\n",
            "strengthens     -> strengthen\n",
            "the             -> the\n",
            "team            -> team\n",
            "’               -> ’\n",
            "s               -> s\n",
            "confidence      -> confidence\n",
            "and             -> and\n",
            "prepares        -> prepare\n",
            "them            -> them\n",
            "for             -> for\n",
            "future          -> future\n",
            "challenges      -> challenge\n",
            ".               -> .\n",
            "The             -> The\n",
            "upcoming        -> upcoming\n",
            "match           -> match\n",
            "is              -> be\n",
            "even            -> even\n",
            "more            -> more\n",
            "important       -> important\n",
            ",               -> ,\n",
            "as              -> a\n",
            "the             -> the\n",
            "team            -> team\n",
            "is              -> be\n",
            "competing       -> compete\n",
            "for             -> for\n",
            "a               -> a\n",
            "spot            -> spot\n",
            "in              -> in\n",
            "the             -> the\n",
            "finals          -> final\n",
            ".               -> .\n",
            "Analysts        -> Analysts\n",
            "agree           -> agree\n",
            "that            -> that\n",
            "if              -> if\n",
            "the             -> the\n",
            "team            -> team\n",
            "continues       -> continue\n",
            "to              -> to\n",
            "show            -> show\n",
            "this            -> this\n",
            "level           -> level\n",
            "of              -> of\n",
            "teamwork        -> teamwork\n",
            "and             -> and\n",
            "discipline      -> discipline\n",
            ",               -> ,\n",
            "they            -> they\n",
            "have            -> have\n",
            "a               -> a\n",
            "strong          -> strong\n",
            "chance          -> chance\n",
            "of              -> of\n",
            "winning         -> win\n",
            "the             -> the\n",
            "entire          -> entire\n",
            "championship    -> championship\n",
            ".               -> .\n",
            "In              -> In\n",
            "the             -> the\n",
            "end             -> end\n",
            ",               -> ,\n",
            "the             -> the\n",
            "team            -> team\n",
            "proved          -> prove\n",
            "that            -> that\n",
            "success         -> success\n",
            "is              -> be\n",
            "not             -> not\n",
            "just            -> just\n",
            "about           -> about\n",
            "individual      -> individual\n",
            "talent          -> talent\n",
            "but             -> but\n",
            "about           -> about\n",
            "unity           -> unity\n",
            ",               -> ,\n",
            "effort          -> effort\n",
            ",               -> ,\n",
            "and             -> and\n",
            "the             -> the\n",
            "shared          -> shared\n",
            "goal            -> goal\n",
            "of              -> of\n",
            "winning         -> win\n",
            "the             -> the\n",
            "championship    -> championship\n",
            ".               -> .\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Kratka usporedba:\n",
            "- spaCy koristi svoj ugrađeni lematizator vezan uz jezični model.\n",
            "- NLTK se oslanja na WordNet i točnost ovisi o POS oznakama koje dodijelimo riječi.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Izvorni tekst:\")\n",
        "print(my_text)\n",
        "print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
        "\n",
        "print(\"Lematizacija sa spaCy (token -> lemma):\")\n",
        "doc_custom = nlp(my_text)\n",
        "spacy_lemmas = [(token.text, token.lemma_) for token in doc_custom]\n",
        "for tok, lem in spacy_lemmas:\n",
        "    print(f\"{tok:15s} -> {lem}\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
        "\n",
        "print(\"Lematizacija s NLTK (token -> lemma):\")\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def get_wordnet_pos(tag):\n",
        "    \"\"\"Map NLTK POS tag na WordNet POS oznaku.\"\"\"\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN  # default\n",
        "\n",
        "# POS tagovi za NLTK tokene (iz Zadatka 1)\n",
        "nltk_pos = pos_tag(nltk_tokens)\n",
        "\n",
        "nltk_lemmas = []\n",
        "for word, pos in nltk_pos:\n",
        "    wn_pos = get_wordnet_pos(pos)\n",
        "    lemma = lemmatizer.lemmatize(word, wn_pos)\n",
        "    nltk_lemmas.append((word, lemma))\n",
        "    print(f\"{word:15s} -> {lemma}\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
        "print(\"Kratka usporedba:\")\n",
        "print(\"- spaCy koristi svoj ugrađeni lematizator vezan uz jezični model.\")\n",
        "print(\"- NLTK se oslanja na WordNet i točnost ovisi o POS oznakama koje dodijelimo riječi.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1f1b920",
      "metadata": {
        "id": "e1f1b920"
      },
      "source": [
        "## 5. POS (Part-of-Speech) označavanje\n",
        "POS označavanje dodjeljuje gramatičku ulogu svakoj riječi (imenica, glagol, pridjev, prilog...)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b25fb76c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b25fb76c",
        "outputId": "08d5b031-f614-4f1b-d313-c36df930249a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural         → PROPN  (NNP)\n",
            "Language        → PROPN  (NNP)\n",
            "Processing      → NOUN   (NN)\n",
            "enables         → VERB   (VBZ)\n",
            "computers       → NOUN   (NNS)\n",
            "to              → PART   (TO)\n",
            "understand      → VERB   (VB)\n",
            "human           → ADJ    (JJ)\n",
            "language        → NOUN   (NN)\n",
            ".               → PUNCT  (.)\n"
          ]
        }
      ],
      "source": [
        "for token in doc:\n",
        "    print(f'{token.text:15} → {token.pos_:6} ({token.tag_})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fe46861f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe46861f",
        "outputId": "37974fd5-9b3c-4c7a-de31-01bef5b00def"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural         → JJ\n",
            "Language        → NNP\n",
            "Processing      → NNP\n",
            "enables         → VBZ\n",
            "computers       → NNS\n",
            "to              → TO\n",
            "understand      → VB\n",
            "human           → JJ\n",
            "language        → NN\n",
            ".               → .\n"
          ]
        }
      ],
      "source": [
        "pos_tags = pos_tag(tokens)\n",
        "for word, tag in pos_tags:\n",
        "    print(f'{word:15} → {tag}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3de5688",
      "metadata": {
        "id": "a3de5688"
      },
      "source": [
        "### Zadatak 4\n",
        "Izdvoji sve imenice i glagole iz svog teksta pomoću jedne od biblioteka."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "d93a5e36",
      "metadata": {
        "id": "d93a5e36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95f06f4-eb39-4a56-b492-a0f1fb668934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Izvorni tekst:\n",
            "\n",
            "The team played an intense match last night, delivering one of their strongest performances this season.\n",
            "Throughout the match, the team demonstrated exceptional teamwork, discipline, and determination.\n",
            "The coach repeatedly emphasized how important teamwork was for maintaining control during the most difficult moments of the match.\n",
            "Several players mentioned that the team had trained specifically to improve their teamwork and communication, which clearly paid off.\n",
            "Fans celebrated loudly after the match, recognizing that the team’s victory was crucial for improving their position in the championship.\n",
            "During the press conference, the coach praised the players for their strategy, dedication, and ability to adapt as the match progressed.\n",
            "He highlighted that every victory strengthens the team’s confidence and prepares them for future challenges.\n",
            "The upcoming match is even more important, as the team is competing for a spot in the finals.\n",
            "Analysts agree that if the team continues to show this level of teamwork and discipline, they have a strong chance of winning the entire championship.\n",
            "In the end, the team proved that success is not just about individual talent but about unity, effort, and the shared goal of winning the championship.\n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Imenice u tekstu:\n",
            "['team', 'match', 'night', 'performances', 'season', 'match', 'team', 'teamwork', 'discipline', 'determination', 'coach', 'teamwork', 'control', 'moments', 'match', 'players', 'team', 'teamwork', 'communication', 'Fans', 'match', 'team', 'victory', 'position', 'championship', 'press', 'conference', 'coach', 'players', 'strategy', 'dedication', 'ability', 'match', 'victory', 'team', 'confidence', 'challenges', 'match', 'team', 'spot', 'finals', 'Analysts', 'team', 'level', 'teamwork', 'discipline', 'chance', 'championship', 'end', 'team', 'success', 'talent', 'unity', 'effort', 'goal', 'championship']\n",
            "\n",
            "Glagoli u tekstu:\n",
            "['played', 'delivering', 'demonstrated', 'emphasized', 'maintaining', 'mentioned', 'trained', 'improve', 'paid', 'celebrated', 'recognizing', 'improving', 'praised', 'adapt', 'progressed', 'highlighted', 'strengthens', 'prepares', 'competing', 'agree', 'continues', 'show', 'have', 'winning', 'proved', 'shared', 'winning']\n",
            "\n",
            "Napomena:\n",
            "- spaCy prepoznaje POS oznake prema jezičnom modelu.\n",
            "- Rezultat ovisi o kontekstu rečenice i samom modelu (en_core_web_sm).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Izvorni tekst:\")\n",
        "print(my_text)\n",
        "print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
        "\n",
        "doc_custom = nlp(my_text)\n",
        "\n",
        "nouns = [token.text for token in doc_custom if token.pos_ == \"NOUN\"]\n",
        "verbs = [token.text for token in doc_custom if token.pos_ == \"VERB\"]\n",
        "\n",
        "print(\"Imenice u tekstu:\")\n",
        "print(nouns)\n",
        "\n",
        "print(\"\\nGlagoli u tekstu:\")\n",
        "print(verbs)\n",
        "\n",
        "print(\"\\nNapomena:\")\n",
        "print(\"- spaCy prepoznaje POS oznake prema jezičnom modelu.\")\n",
        "print(\"- Rezultat ovisi o kontekstu rečenice i samom modelu (en_core_web_sm).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b5de9a2",
      "metadata": {
        "id": "6b5de9a2"
      },
      "source": [
        "## 6. Zadaci"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47b84243",
      "metadata": {
        "id": "47b84243"
      },
      "source": [
        "## Zadatak 1: Usporedi dva teksta po učestalosti riječi\n",
        "\n",
        "**Opis:**  \n",
        "Analiziraj dva različita teksta (npr. jedan o sportu, drugi o tehnologiji).  \n",
        "Nakon što provedeš tokenizaciju, uklanjanje zaustavnih riječi i lematizaciju, potrebno je:  \n",
        "- pronaći 5 najčešćih imenica u svakom tekstu,  \n",
        "- usporediti liste dobivenih imenica,  \n",
        "- zaključiti o čemu se govori u svakom tekstu.\n",
        "\n",
        "**Cilj:**  \n",
        "Razumjeti kako se analiza frekvencije riječi može koristiti za prepoznavanje teme teksta.\n",
        "\n",
        "**Upute:**  \n",
        "1. Učitaj dva različita teksta (mogu biti dvije rečenice, dva odlomka ili datoteke).  \n",
        "2. Obradi svaki tekst (tokenizacija → čišćenje → lematizacija → POS tagging).  \n",
        "3. Izdvoji samo riječi označene kao NOUN (imenice).  \n",
        "4. Prebroji pojavljivanja i prikaži 5 najčešćih.  \n",
        "5. Zaključi koja je tema svakog teksta."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_sport = \"\"\"\n",
        "The team played an intense match last night, delivering one of their strongest performances this season.\n",
        "Throughout the match, the team demonstrated exceptional teamwork, discipline, and determination.\n",
        "The coach repeatedly emphasized how important teamwork was for maintaining control during the most difficult moments of the match.\n",
        "Several players mentioned that the team had trained specifically to improve their teamwork and communication, which clearly paid off.\n",
        "Fans celebrated loudly after the match, recognizing that the team’s victory was crucial for improving their position in the championship.\n",
        "During the press conference, the coach praised the players for their strategy, dedication, and ability to adapt as the match progressed.\n",
        "He highlighted that every victory strengthens the team’s confidence and prepares them for future challenges.\n",
        "The upcoming match is even more important, as the team is competing for a spot in the finals.\n",
        "Analysts agree that if the team continues to show this level of teamwork and discipline, they have a strong chance of winning the entire championship.\n",
        "In the end, the team proved that success is not just about individual talent but about unity, effort, and the shared goal of winning the championship.\n",
        "\"\"\"\n",
        "\n",
        "text_tech = \"\"\"\n",
        "Modern technology is evolving rapidly, shaping the way people work, communicate, and solve complex problems.\n",
        "New devices and software are developed every year, pushing the boundaries of what modern technology can achieve.\n",
        "Researchers are focusing heavily on artificial intelligence, automation, and advanced data processing to create smarter and more powerful systems.\n",
        "These innovations enable companies to build faster devices, more secure software, and highly efficient solutions for everyday use.\n",
        "Experts believe that artificial intelligence will continue to transform technology by improving decision-making, optimizing workflows, and predicting user needs.\n",
        "Many companies are investing in automation technologies to reduce costs, increase productivity, and eliminate repetitive tasks.\n",
        "At the same time, advancements in data processing make it possible to analyze enormous datasets and identify patterns that were previously impossible to detect.\n",
        "This combination of artificial intelligence, automation, and data processing is driving a new era of modern technology.\n",
        "If current trends continue, technology will become even more integrated into daily life, offering smarter devices, adaptive software, and personalized solutions.\n",
        "Researchers conclude that the future of modern technology depends on continuous innovation, reliable data processing, and the responsible development of artificial intelligence.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "SQXDyoqIBhln"
      },
      "id": "SQXDyoqIBhln",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "def preprocess(t):\n",
        "    t = t.lower()\n",
        "    t = re.sub(r\"[^a-zA-Z]+\", \" \", t)\n",
        "    tokens = t.split()\n",
        "    return tokens\n",
        "\n",
        "tokens1 = preprocess(text_sport)\n",
        "tokens2 = preprocess(text_tech)\n",
        "\n",
        "# 3. Brojanje učestalosti\n",
        "freq1 = Counter(tokens1)\n",
        "freq2 = Counter(tokens2)\n",
        "\n",
        "print(\"Najčešće riječi u tekstu 1:\")\n",
        "print(freq1.most_common(10))\n",
        "\n",
        "print(\"\\nNajčešće riječi u tekstu 2:\")\n",
        "print(freq2.most_common(10))\n",
        "\n",
        "# 4. Usporedba zajedničkih riječi\n",
        "common = set(freq1.keys()) & set(freq2.keys())\n",
        "\n",
        "print(\"\\nZajedničke riječi i njihove frekvencije:\")\n",
        "for w in common:\n",
        "    print(f\"{w:12s}  T1: {freq1[w]}   T2: {freq2[w]}\")\n",
        "\n",
        "print(\"\\nNapomena:\")\n",
        "print(\"- Učestalost pomaže prepoznati tematske jezgre svakog teksta.\")\n",
        "print(\"- Riječi s najvišim frekvencijama sugeriraju glavnu temu i fokus.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU4NkwWCLCz2",
        "outputId": "202c8645-582c-4583-e77a-1efcd7293617"
      },
      "id": "hU4NkwWCLCz2",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Najčešće riječi u tekstu 1:\n",
            "[('the', 24), ('team', 8), ('match', 6), ('and', 6), ('of', 5), ('for', 5), ('that', 5), ('their', 4), ('teamwork', 4), ('to', 3)]\n",
            "\n",
            "Najčešće riječi u tekstu 2:\n",
            "[('and', 11), ('technology', 6), ('to', 6), ('the', 5), ('of', 5), ('modern', 4), ('artificial', 4), ('intelligence', 4), ('data', 4), ('processing', 4)]\n",
            "\n",
            "Zajedničke riječi i njihove frekvencije:\n",
            "to            T1: 3   T2: 6\n",
            "of            T1: 5   T2: 5\n",
            "even          T1: 1   T2: 1\n",
            "every         T1: 1   T2: 1\n",
            "for           T1: 5   T2: 1\n",
            "is            T1: 3   T2: 2\n",
            "this          T1: 2   T2: 1\n",
            "in            T1: 3   T2: 2\n",
            "that          T1: 5   T2: 3\n",
            "the           T1: 24   T2: 5\n",
            "improving     T1: 1   T2: 1\n",
            "more          T1: 1   T2: 3\n",
            "and           T1: 6   T2: 11\n",
            "if            T1: 1   T2: 1\n",
            "a             T1: 2   T2: 1\n",
            "future        T1: 1   T2: 1\n",
            "\n",
            "Napomena:\n",
            "- Učestalost pomaže prepoznati tematske jezgre svakog teksta.\n",
            "- Riječi s najvišim frekvencijama sugeriraju glavnu temu i fokus.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c585b56",
      "metadata": {
        "id": "8c585b56"
      },
      "source": [
        "## Zadatak 2: Analiza tonova (pozitivno vs. negativno)\n",
        "\n",
        "**Opis:**  \n",
        "Zadatak je provesti osnovnu analizu sentimenta.  \n",
        "Potrebno je obraditi nekoliko kratkih recenzija (npr. o filmovima, proizvodima, restoranima) i odrediti jesu li one pozitivne ili negativne.\n",
        "\n",
        "**Cilj:**  \n",
        "Pokazati kako se osnovni NLP alati mogu koristiti za analizu osjećaja u tekstu.\n",
        "\n",
        "**Upute:**  \n",
        "1. Pripremi popise riječi:  \n",
        "   - pozitivne: `[\"good\", \"great\", \"excellent\", \"amazing\", \"nice\", \"wonderful\"]`  \n",
        "   - negativne: `[\"bad\", \"poor\", \"terrible\", \"boring\", \"awful\", \"disappointing\"]`  \n",
        "2. Za svaku recenziju:  \n",
        "   - očisti tekst (ukloni stopwords, lematiziraj),  \n",
        "   - prebroji koliko pozitivnih i negativnih riječi sadrži.  \n",
        "3. Na temelju rezultata zaključi ton svake recenzije.  \n",
        "4. (Opcionalno) Prikaži rezultate u tablici ili grafu."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "text = \"\"\"\n",
        "I really love how this project turned out. The results are amazing and wonderful,\n",
        "but the process was sometimes bad and terrible, with a few horrible moments.\n",
        "\"\"\"\n",
        "\n",
        "positive_words = [\"good\", \"great\", \"excellent\", \"happy\", \"love\", \"amazing\", \"nice\", \"wonderful\"]\n",
        "negative_words = [\"bad\", \"terrible\", \"awful\", \"sad\", \"hate\", \"horrible\", \"disgusting\", \"poor\"]\n",
        "\n",
        "def preprocess(t):\n",
        "    t = t.lower()\n",
        "    t = re.sub(r\"[^a-zA-Z]+\", \" \", t)\n",
        "    tokens = t.split()\n",
        "    return tokens\n",
        "\n",
        "tokens = preprocess(text)\n",
        "freq = Counter(tokens)\n",
        "\n",
        "pos_count = sum(freq[w] for w in positive_words if w in freq)\n",
        "neg_count = sum(freq[w] for w in negative_words if w in freq)\n",
        "\n",
        "print(\"Ukupno riječi u tekstu:\", len(tokens))\n",
        "print(\"Pozitivne riječi:\", pos_count)\n",
        "print(\"Negativne riječi:\", neg_count)\n",
        "print()\n",
        "\n",
        "print(\"Pozitivne riječi koje su se pojavile:\")\n",
        "for w in positive_words:\n",
        "    if w in freq:\n",
        "        print(f\"{w:12s} -> {freq[w]}\")\n",
        "\n",
        "print(\"\\nNegativne riječi koje su se pojavile:\")\n",
        "for w in negative_words:\n",
        "    if w in freq:\n",
        "        print(f\"{w:12s} -> {freq[w]}\")\n",
        "\n",
        "print(\"\\nProcjena tona teksta:\")\n",
        "if pos_count > neg_count:\n",
        "    print(\"Tekst je pretežno POZITIVAN.\")\n",
        "elif neg_count > pos_count:\n",
        "    print(\"Tekst je pretežno NEGATIVAN.\")\n",
        "else:\n",
        "    print(\"Tekst je NEODREĐEN ili balansiran između pozitivnog i negativnog.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKfeuqvHLIKF",
        "outputId": "9a7cd9c6-1808-470f-9a00-b9cadd69cb22"
      },
      "id": "VKfeuqvHLIKF",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ukupno riječi u tekstu: 27\n",
            "Pozitivne riječi: 3\n",
            "Negativne riječi: 3\n",
            "\n",
            "Pozitivne riječi koje su se pojavile:\n",
            "love         -> 1\n",
            "amazing      -> 1\n",
            "wonderful    -> 1\n",
            "\n",
            "Negativne riječi koje su se pojavile:\n",
            "bad          -> 1\n",
            "terrible     -> 1\n",
            "horrible     -> 1\n",
            "\n",
            "Procjena tona teksta:\n",
            "Tekst je NEODREĐEN ili balansiran između pozitivnog i negativnog.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29571374",
      "metadata": {
        "id": "29571374"
      },
      "source": [
        "## Zadatak 3: Uredi nered/pronađi lažne riječi\n",
        "\n",
        "**Opis:**  \n",
        "Zadan je tekst koji sadrži izmišljene riječi ili “šum”.  \n",
        "Zadatak je pronaći riječi koje nisu prepoznate u jezičnom modelu (engl. *out of vocabulary words*).\n",
        "\n",
        "**Cilj:**  \n",
        "Razumjeti kako model prepoznaje poznate i nepoznate riječi te kako to može pomoći u detekciji pogrešaka u tekstu.\n",
        "\n",
        "**Upute:**  \n",
        "1. Unesi tekst koji sadrži besmislene riječi (npr. „The data blorp is analyzed using great accuracy flom.“).  \n",
        "2. Tokeniziraj tekst pomoću spaCy modela.  \n",
        "3. Provjeri svaku riječ pomoću `token.is_oov`, ako vrati `True`, riječ nije prepoznata.  \n",
        "4. Ispiši popis “nepoznatih” riječi.  \n",
        "5. (Opcionalno) Očisti tekst uklanjanjem tih riječi."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24cce210",
      "metadata": {
        "id": "24cce210"
      },
      "source": [
        "**Tekst:**\n",
        "\n",
        "> In the future, artificel intellgence will revolutionize the way we interract with technolodgy.  \n",
        "> Peaple might use smart assistents not only for work but also for personal healtcare and educattion.  \n",
        "> Yet, as systems become more compicated, ensuring data privasy and securrity will be crucial.  \n",
        "> The recent blonix project already shows how mashine learning can adapt to dynamic enviroments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "70699761",
      "metadata": {
        "id": "70699761"
      },
      "outputs": [],
      "source": [
        "text33 = \"\"\"\n",
        "In the future, artificel intellgence will revolutionize the way we interract with technolodgy.\n",
        "Peaple might use smart assistents not only for work but also for personal healtcare and educattion.\n",
        "Yet, as systems become more compicated, ensuring data privasy and securrity will be crucial.\n",
        "The recent blonix project already shows how mashine learning can adapt to dynamic enviroments.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import words\n",
        "\n",
        "nltk.download('words')\n",
        "\n",
        "english_words = set(w.lower() for w in words.words())\n",
        "\n",
        "def preprocess(t):\n",
        "    t = t.lower()\n",
        "    t = re.sub(r\"[^a-z\\s]+\", \" \", t)\n",
        "    tokens = t.split()\n",
        "    return tokens\n",
        "\n",
        "tokens = preprocess(text33)\n",
        "\n",
        "real_words = []\n",
        "fake_words = []\n",
        "\n",
        "for tok in tokens:\n",
        "    if tok in english_words:\n",
        "        real_words.append(tok)\n",
        "    else:\n",
        "        fake_words.append(tok)\n",
        "\n",
        "print(\"Svi tokeni:\")\n",
        "print(tokens)\n",
        "\n",
        "print(\"\\nStvarne riječi (pronađene u NLTK rječniku):\")\n",
        "print(sorted(set(real_words)))\n",
        "\n",
        "print(\"\\nSumnjive / lažne riječi (nisu u rječniku):\")\n",
        "print(sorted(set(fake_words)))\n",
        "\n",
        "print(\"\\nNapomena:\")\n",
        "print(\"- 'Lažne' riječi mogu biti i tipfeleri ili rijetke/morfološki promijenjene riječi.\")\n",
        "print(\"- Ovo je gruba heuristika, ali dobro pokazuje ideju čišćenja teksta.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHpuhFQYWaom",
        "outputId": "9e0dcea3-94c8-46d0-e9ea-1bdaf03a4e21"
      },
      "id": "hHpuhFQYWaom",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Svi tokeni:\n",
            "['in', 'the', 'future', 'artificel', 'intellgence', 'will', 'revolutionize', 'the', 'way', 'we', 'interract', 'with', 'technolodgy', 'peaple', 'might', 'use', 'smart', 'assistents', 'not', 'only', 'for', 'work', 'but', 'also', 'for', 'personal', 'healtcare', 'and', 'educattion', 'yet', 'as', 'systems', 'become', 'more', 'compicated', 'ensuring', 'data', 'privasy', 'and', 'securrity', 'will', 'be', 'crucial', 'the', 'recent', 'blonix', 'project', 'already', 'shows', 'how', 'mashine', 'learning', 'can', 'adapt', 'to', 'dynamic', 'enviroments']\n",
            "\n",
            "Stvarne riječi (pronađene u NLTK rječniku):\n",
            "['adapt', 'already', 'also', 'and', 'as', 'be', 'become', 'but', 'can', 'crucial', 'data', 'dynamic', 'for', 'future', 'how', 'in', 'learning', 'might', 'more', 'not', 'only', 'personal', 'project', 'recent', 'revolutionize', 'smart', 'the', 'to', 'use', 'way', 'we', 'will', 'with', 'work', 'yet']\n",
            "\n",
            "Sumnjive / lažne riječi (nisu u rječniku):\n",
            "['artificel', 'assistents', 'blonix', 'compicated', 'educattion', 'ensuring', 'enviroments', 'healtcare', 'intellgence', 'interract', 'mashine', 'peaple', 'privasy', 'securrity', 'shows', 'systems', 'technolodgy']\n",
            "\n",
            "Napomena:\n",
            "- 'Lažne' riječi mogu biti i tipfeleri ili rijetke/morfološki promijenjene riječi.\n",
            "- Ovo je gruba heuristika, ali dobro pokazuje ideju čišćenja teksta.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6079cbe4",
      "metadata": {
        "id": "6079cbe4"
      },
      "source": [
        "## Zadatak 4: Tko govori o čemu?\n",
        "\n",
        "**Opis:**  \n",
        "Imate tri različita teksta iz različitih domena (npr. politika, sport, znanost).  \n",
        "Nakon obrade potrebno je prepoznati kojoj temi pojedini tekst pripada, koristeći najčešće riječi.\n",
        "\n",
        "**Cilj:**  \n",
        "Povezati statističku analizu riječi s prepoznavanjem teme teksta —> osnova za automatsku klasifikaciju dokumenata.\n",
        "\n",
        "**Upute:**  \n",
        "1. Pripremi tri teksta različitih tema.  \n",
        "2. Obradi svaki tekst kroz cijeli NLP postupak.  \n",
        "3. Izvuci 5 najčešćih imenica i glagola.  \n",
        "4. Na temelju tih riječi pokušaj zaključiti o čemu tekst govori.  \n",
        "5. (Opcionalno) Napravi jednostavan graf koji prikazuje razlike među tekstovima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "72eb1ec9",
      "metadata": {
        "id": "72eb1ec9"
      },
      "outputs": [],
      "source": [
        "text_1 = \"\"\"\n",
        "The government has introduced a series of new reforms designed to improve economic stability and strengthen national policy.\n",
        "According to officials, the government believes these reforms will help reduce inflation and increase trust in public institutions.\n",
        "During a press conference, government representatives explained that the policy focuses on long-term economic growth, responsible budgeting, and transparent decision-making.\n",
        "Opposition leaders criticized the government, arguing that the reforms do not address the root causes of inflation and may place additional pressure on the middle-class population.\n",
        "Despite the criticism, the prime minister emphasized that the government must take decisive action to protect the economy.\n",
        "He stated that the policy is essential for maintaining stability, supporting national programs, and ensuring that citizens benefit from a more resilient economic system.\n",
        "The government also announced consultations with economic experts to refine the policy and monitor inflation trends.\n",
        "Overall, the government insists that the reforms represent a necessary step toward financial responsibility and sustainable development.\n",
        "\"\"\"\n",
        "\n",
        "text_2 = \"\"\"\n",
        "The team delivered an outstanding performance last night, playing one of the most intense matches of the season.\n",
        "Throughout the match, the team showed great determination, teamwork, and discipline.\n",
        "The coach praised the team for maintaining focus and adapting their strategy as the match progressed.\n",
        "Fans celebrated loudly, recognizing that the team’s victory was crucial for securing their position in the championship rankings.\n",
        "During the post-match interview, the coach highlighted how preparation and teamwork were essential for winning such a competitive match.\n",
        "Several players said that the team felt more united than ever, and that their teamwork was the key factor in overcoming the toughest opponents.\n",
        "The next match will be even more important, as the team aims to qualify for the finals.\n",
        "If the team continues to play with this level of teamwork and discipline, they have a strong chance of winning the entire championship.\n",
        "\"\"\"\n",
        "\n",
        "text_3 = \"\"\"\n",
        "Researchers at the university have developed a new material that significantly improves energy storage efficiency.\n",
        "The material was tested under various laboratory conditions, and researchers observed that the material maintained its structure even when exposed to high temperatures.\n",
        "According to the study, the material could transform the future of renewable energy by enabling more stable and long-lasting storage systems.\n",
        "Scientists believe that energy demand will continue to rise, making the development of advanced material technologies essential for sustainable production.\n",
        "The research team plans to publish additional data as they continue studying the material and its impact on battery performance.\n",
        "Several researchers have already suggested that this material could replace current lithium-based components used in many energy systems.\n",
        "If the material continues to show positive results, it may revolutionize energy production and create new opportunities for scientific innovation.\n",
        "Overall, the study highlights the importance of energy research and the potential of this new material to reshape modern technology.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "texts = {\n",
        "    \"Govornik A\": text_1,\n",
        "    \"Govornik B\": text_2,\n",
        "    \"Govornik C\": text_3,\n",
        "}\n",
        "\n",
        "def analyze_text(label, text):\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"{label}\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    doc = nlp(text)\n",
        "\n",
        "    nouns = []\n",
        "    verbs = []\n",
        "\n",
        "    for token in doc:\n",
        "        # preskoči stop-riječi, interpunkciju, razmake\n",
        "        if token.is_stop or token.is_punct or token.is_space:\n",
        "            continue\n",
        "\n",
        "        # koristimo lemu da bismo grupirali oblike riječi\n",
        "        if token.pos_ == \"NOUN\":\n",
        "            nouns.append(token.lemma_.lower())\n",
        "        elif token.pos_ == \"VERB\":\n",
        "            verbs.append(token.lemma_.lower())\n",
        "\n",
        "    noun_counts = Counter(nouns)\n",
        "    verb_counts = Counter(verbs)\n",
        "\n",
        "    print(\"Top 5 imenica:\")\n",
        "    for word, cnt in noun_counts.most_common(5):\n",
        "        print(f\"{word:20s} -> {cnt}\")\n",
        "\n",
        "    print(\"\\nTop 5 glagola:\")\n",
        "    for word, cnt in verb_counts.most_common(5):\n",
        "        print(f\"{word:20s} -> {cnt}\")\n",
        "\n",
        "    print(\"\\nKratki zaključak:\")\n",
        "    print(\"- Imenice otkrivaju TEME o kojima govornik priča.\")\n",
        "    print(\"- Glagoli otkrivaju RADNJE, što se događa ili što se želi postići.\")\n",
        "    print(\"- Usporedbom govornika možeš vidjeti tko priča o podacima, tko o klimi, tko o razvoju softvera.\\n\")\n",
        "\n",
        "\n",
        "# 2. Analiza svih govornika\n",
        "for label, txt in texts.items():\n",
        "    analyze_text(label, txt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtP0DmSsWxkA",
        "outputId": "35bdf122-b42a-4945-eac8-33ab4436e8a2"
      },
      "id": "VtP0DmSsWxkA",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Govornik A\n",
            "======================================================================\n",
            "\n",
            "Top 5 imenica:\n",
            "government           -> 7\n",
            "reform               -> 4\n",
            "policy               -> 4\n",
            "inflation            -> 3\n",
            "stability            -> 2\n",
            "\n",
            "Top 5 glagola:\n",
            "introduce            -> 1\n",
            "design               -> 1\n",
            "improve              -> 1\n",
            "strengthen           -> 1\n",
            "accord               -> 1\n",
            "\n",
            "Kratki zaključak:\n",
            "- Imenice otkrivaju TEME o kojima govornik priča.\n",
            "- Glagoli otkrivaju RADNJE, što se događa ili što se želi postići.\n",
            "- Usporedbom govornika možeš vidjeti tko priča o podacima, tko o klimi, tko o razvoju softvera.\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Govornik B\n",
            "======================================================================\n",
            "\n",
            "Top 5 imenica:\n",
            "team                 -> 7\n",
            "match                -> 5\n",
            "teamwork             -> 4\n",
            "discipline           -> 2\n",
            "coach                -> 2\n",
            "\n",
            "Top 5 glagola:\n",
            "play                 -> 2\n",
            "win                  -> 2\n",
            "deliver              -> 1\n",
            "show                 -> 1\n",
            "praise               -> 1\n",
            "\n",
            "Kratki zaključak:\n",
            "- Imenice otkrivaju TEME o kojima govornik priča.\n",
            "- Glagoli otkrivaju RADNJE, što se događa ili što se želi postići.\n",
            "- Usporedbom govornika možeš vidjeti tko priča o podacima, tko o klimi, tko o razvoju softvera.\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Govornik C\n",
            "======================================================================\n",
            "\n",
            "Top 5 imenica:\n",
            "material             -> 9\n",
            "energy               -> 6\n",
            "researcher           -> 3\n",
            "storage              -> 2\n",
            "study                -> 2\n",
            "\n",
            "Top 5 glagola:\n",
            "continue             -> 3\n",
            "develop              -> 1\n",
            "improve              -> 1\n",
            "test                 -> 1\n",
            "observe              -> 1\n",
            "\n",
            "Kratki zaključak:\n",
            "- Imenice otkrivaju TEME o kojima govornik priča.\n",
            "- Glagoli otkrivaju RADNJE, što se događa ili što se želi postići.\n",
            "- Usporedbom govornika možeš vidjeti tko priča o podacima, tko o klimi, tko o razvoju softvera.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a023ccd",
      "metadata": {
        "id": "3a023ccd"
      },
      "source": [
        "## Zadatak 5: Analiza političkih govora (napredni zadatak)\n",
        "\n",
        "> **Opis:**  \n",
        "> U ovom zadatku treba analizirati tekstove političkih govora i otkriti koje riječi govornici najčešće koriste kako bi naglasili svoje poruke.  \n",
        "> Cilj je otkriti koje teme i koje vrste riječi dominiraju u govoru.\n",
        "\n",
        "---\n",
        "\n",
        "**Upute:**\n",
        "1. Pronađi ili kopiraj dva kratka govora (ili odlomka) poznatih političara.  \n",
        "   Ako nemaš stvarne govore, možeš koristiti dva primjera niže.  \n",
        "2. Za svaki govor napravi kompletnu obradu teksta:\n",
        "   - tokenizacija  \n",
        "   - uklanjanje zaustavnih riječi  \n",
        "   - lematizacija  \n",
        "   - POS tagging  \n",
        "3. Izdvoji:\n",
        "   - 10 **imenica**,  \n",
        "   - 10 **glagola**,  \n",
        "   - 10 **pridjeva**.  \n",
        "4. Prikaži rezultate u **tri odvojene tablice** ili **grafovima** (koristi `pandas` i `matplotlib`).  \n",
        "5. Usporedi govore i pokušaj zaključiti:\n",
        "   - Koji govor je “pozitivniji” (više koristi riječi poput *hope*, *future*, *together*)  \n",
        "   - Koji je “defanzivniji” ili “konfliktniji” (više koristi riječi poput *fight*, *challenge*, *threat*).  \n",
        "6. Na kraju napiši **kratki zaključak (2–3 rečenice)**: kako se teme razlikuju i što dominira u svakom govoru.\n",
        "\n",
        "---\n",
        "\n",
        "**Cilj:**  \n",
        "Ovim zadatkom studenti povezuju sve što su naučili, obradu, analizu i interpretaciju teksta, u jednu cjelinu, simulirajući osnovnu NLP analizu stvarnih podataka.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "Ck_vcgjYb9IN"
      },
      "id": "Ck_vcgjYb9IN",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "text_A = \"\"\"My fellow citizens, today we gather not as strangers, but as a community united by our shared hopes and dreams.\n",
        "We stand at the dawn of a new era—one built on innovation, cooperation, and the unshakable belief in the potential of our people.\n",
        "The challenges before us are great, but so too is our courage and creativity.\n",
        "We will invest in education, protect our planet, and empower every individual to shape their own destiny.\n",
        "\n",
        "Let us build bridges, not walls; extend hands, not fists.\n",
        "Together, we can create a nation where opportunity is not limited to the few, but shared by all.\n",
        "Our strength lies not in fear, but in faith—in each other, in our values, and in the bright future we will create together.\n",
        "\n",
        "Let this be the generation that chooses unity over division, progress over stagnation, and hope over despair.\n",
        "Let this be the generation that dares to dream boldly, that embraces change, and that lifts one another up rather than tearing each other down.\n",
        "\n",
        "We will work to expand access to healthcare, to ensure that no family has to choose between medicine and food.\n",
        "We will support our teachers, invest in our children, and build schools that prepare every young mind for the world of tomorrow.\n",
        "We will encourage clean energy, sustainable development, and responsible stewardship of the natural resources entrusted to us.\n",
        "\n",
        "And above all, we will choose compassion—compassion for our neighbors, for our communities, and for those whose voices too often go unheard.\n",
        "Our nation is strongest when every citizen feels seen, valued, and empowered.\n",
        "\n",
        "Together, we will write a new chapter in our nation’s story—one defined not by fear or division, but by courage, unity, and purpose.\n",
        "A future filled with opportunity is within our reach, and it is a future we will build hand in hand.\n",
        "Let us move forward with confidence, with optimism, and with unwavering hope in all that we can achieve—together.\n",
        "\"\"\"\n",
        "\n",
        "text_B = \"\"\"My fellow citizens, the world we face today is uncertain and full of danger.\n",
        "Across the globe, our values are challenged, our security is tested, and our freedom is under threat.\n",
        "We cannot afford complacency or hesitation.\n",
        "We must strengthen our defenses, protect our borders, and ensure the safety of our families and our future.\n",
        "\n",
        "Our enemies seek to divide us, to weaken our resolve, and to spread fear and chaos.\n",
        "But we will not yield.\n",
        "We will act with determination, discipline, and strength.\n",
        "Every citizen has a role to play in defending our nation and preserving our way of life.\n",
        "\n",
        "We must increase our vigilance, enhance our intelligence capabilities, and give our armed forces the tools they need to counter every threat.\n",
        "We must stand firm against those who wish to undermine our democracy, whether they act from within or from beyond our borders.\n",
        "\n",
        "Let us face the challenges before us with courage, and together ensure that the next generation inherits not fear, but freedom—not weakness, but resilience.\n",
        "We will confront extremism wherever it appears.\n",
        "We will push back against hostile powers seeking to disrupt our alliances.\n",
        "We will safeguard our economy from manipulation and ensure that our industries cannot be exploited by those who do not share our values.\n",
        "\n",
        "The dangers we confront are real, and they are growing.\n",
        "Cyberattacks, disinformation campaigns, and coordinated acts of aggression threaten our stability.\n",
        "We cannot ignore these warnings; we must respond with unity and unwavering resolve.\n",
        "\n",
        "We will reinforce our border security, support law enforcement, and empower our military to defend every inch of our homeland.\n",
        "We will stand shoulder to shoulder, refusing to be intimidated, refusing to be divided, and refusing to surrender to forces that thrive on fear.\n",
        "\n",
        "Together, we will ensure that our nation remains safe, strong, and unbroken.\n",
        "We will rise to meet every threat, overcome every obstacle, and protect the sacred freedoms that define us.\n",
        "This is our duty, our responsibility, and our promise to all who come after us.\n",
        "\"\"\"\n",
        "\n",
        "speeches = {\n",
        "    \"Govor A – inkluzija, nada, progres\": text_A,\n",
        "    \"Govor B – prijetnje, sigurnost, obrana\": text_B,\n",
        "}\n",
        "\n",
        "positive_words = [\n",
        "    \"growth\", \"prosper\", \"innovation\", \"clean\", \"future\",\n",
        "    \"trust\", \"fair\", \"justice\", \"peace\", \"support\", \"courage\",\n",
        "    \"solidarity\", \"strong\", \"recover\", \"hope\", \"unity\", \"progress\",\n",
        "    \"opportunity\", \"compassion\", \"confidence\", \"optimism\", \"resilience\"\n",
        "]\n",
        "\n",
        "negative_words = [\n",
        "    \"crisis\", \"corruption\", \"injustice\", \"struggle\",\n",
        "    \"poverty\", \"fear\", \"violence\", \"unemployment\",\n",
        "    \"broken\", \"division\", \"conflict\", \"danger\", \"threat\",\n",
        "    \"chaos\", \"hostile\", \"aggression\"\n",
        "]\n",
        "\n",
        "def analyze_speech(label, text):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(label)\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "    doc = nlp(text)\n",
        "\n",
        "    content_tokens = [\n",
        "        token for token in doc\n",
        "        if not token.is_stop and not token.is_punct and not token.is_space\n",
        "    ]\n",
        "\n",
        "    lemmas = [token.lemma_.lower() for token in content_tokens]\n",
        "    nouns = [token.lemma_.lower() for token in content_tokens if token.pos_ == \"NOUN\"]\n",
        "    verbs = [token.lemma_.lower() for token in content_tokens if token.pos_ == \"VERB\"]\n",
        "\n",
        "    lemma_counts = Counter(lemmas)\n",
        "    noun_counts = Counter(nouns)\n",
        "    verb_counts = Counter(verbs)\n",
        "\n",
        "    # Sentiment-skica\n",
        "    pos_count = sum(lemma_counts[w] for w in positive_words if w in lemma_counts)\n",
        "    neg_count = sum(lemma_counts[w] for w in negative_words if w in lemma_counts)\n",
        "\n",
        "    print(\"Top 10 sadržajnih riječi (leme):\")\n",
        "    for w, c in lemma_counts.most_common(10):\n",
        "        print(f\"{w:20s} -> {c}\")\n",
        "\n",
        "    print(\"\\nTop 5 imenica:\")\n",
        "    for w, c in noun_counts.most_common(5):\n",
        "        print(f\"{w:20s} -> {c}\")\n",
        "\n",
        "    print(\"\\nTop 5 glagola:\")\n",
        "    for w, c in verb_counts.most_common(5):\n",
        "        print(f\"{w:20s} -> {c}\")\n",
        "\n",
        "    print(\"\\nProcjena tona govora (vrlo pojednostavljena):\")\n",
        "    print(f\"Pozitivne riječi: {pos_count}\")\n",
        "    print(f\"Negativne riječi: {neg_count}\")\n",
        "\n",
        "    if pos_count > neg_count:\n",
        "        print(\"→ Govor ima pretežno POZITIVAN naglasak.\")\n",
        "    elif neg_count > pos_count:\n",
        "        print(\"→ Govor ima pretežno NEGATIVAN / sigurnosno-krizni naglasak.\")\n",
        "    else:\n",
        "        print(\"→ Govor je tonalno balansiran ili neodređen.\")\n",
        "\n",
        "    print(\"\\nKratki zaključak:\")\n",
        "    print(\"- Dominantne imenice otkrivaju glavne TEME (npr. unity, opportunity vs. threat, security).\")\n",
        "    print(\"- Dominantni glagoli otkrivaju ti1pične AKCIJE (invest, build, support vs. defend, strengthen, confront).\")\n",
        "    print(\"- Omjer pozitivnih i negativnih riječi daje grubu, ali jasnu sliku retoričkog smjera.\\n\")\n",
        "\n",
        "\n",
        "# 3) Analiza oba govora\n",
        "for label, speech in speeches.items():\n",
        "    analyze_speech(label, speech)\n"
      ],
      "metadata": {
        "id": "DF8ymaqucBd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a2ea19-d756-4f95-d23a-0f15f5017c1c"
      },
      "id": "DF8ymaqucBd8",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Govor A – inkluzija, nada, progres\n",
            "================================================================================\n",
            "\n",
            "Top 10 sadržajnih riječi (leme):\n",
            "build                -> 4\n",
            "let                  -> 4\n",
            "hope                 -> 3\n",
            "hand                 -> 3\n",
            "nation               -> 3\n",
            "future               -> 3\n",
            "choose               -> 3\n",
            "citizen              -> 2\n",
            "community            -> 2\n",
            "share                -> 2\n",
            "\n",
            "Top 5 imenica:\n",
            "hand                 -> 3\n",
            "nation               -> 3\n",
            "future               -> 3\n",
            "citizen              -> 2\n",
            "community            -> 2\n",
            "\n",
            "Top 5 glagola:\n",
            "build                -> 4\n",
            "let                  -> 4\n",
            "choose               -> 3\n",
            "share                -> 2\n",
            "invest               -> 2\n",
            "\n",
            "Procjena tona govora (vrlo pojednostavljena):\n",
            "Pozitivne riječi: 21\n",
            "Negativne riječi: 4\n",
            "→ Govor ima pretežno POZITIVAN naglasak.\n",
            "\n",
            "Kratki zaključak:\n",
            "- Dominantne imenice otkrivaju glavne TEME (npr. unity, opportunity vs. threat, security).\n",
            "- Dominantni glagoli otkrivaju tipične AKCIJE (invest, build, support vs. defend, strengthen, confront).\n",
            "- Omjer pozitivnih i negativnih riječi daje grubu, ali jasnu sliku retoričkog smjera.\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Govor B – prijetnje, sigurnost, obrana\n",
            "================================================================================\n",
            "\n",
            "Top 10 sadržajnih riječi (leme):\n",
            "ensure               -> 4\n",
            "freedom              -> 3\n",
            "threat               -> 3\n",
            "border               -> 3\n",
            "fear                 -> 3\n",
            "act                  -> 3\n",
            "refuse               -> 3\n",
            "citizen              -> 2\n",
            "face                 -> 2\n",
            "danger               -> 2\n",
            "\n",
            "Top 5 imenica:\n",
            "freedom              -> 3\n",
            "threat               -> 3\n",
            "border               -> 3\n",
            "citizen              -> 2\n",
            "danger               -> 2\n",
            "\n",
            "Top 5 glagola:\n",
            "ensure               -> 4\n",
            "refuse               -> 3\n",
            "face                 -> 2\n",
            "protect              -> 2\n",
            "seek                 -> 2\n",
            "\n",
            "Procjena tona govora (vrlo pojednostavljena):\n",
            "Pozitivne riječi: 6\n",
            "Negativne riječi: 11\n",
            "→ Govor ima pretežno NEGATIVAN / sigurnosno-krizni naglasak.\n",
            "\n",
            "Kratki zaključak:\n",
            "- Dominantne imenice otkrivaju glavne TEME (npr. unity, opportunity vs. threat, security).\n",
            "- Dominantni glagoli otkrivaju tipične AKCIJE (invest, build, support vs. defend, strengthen, confront).\n",
            "- Omjer pozitivnih i negativnih riječi daje grubu, ali jasnu sliku retoričkog smjera.\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}